# MAVO ìŒì„± ë¶„ì„ í”Œë¡œìš° ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

MAVOëŠ” ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³ , ì „ì‚¬(STT), í™”ì ë¶„ë¦¬(Diarization), í…ìŠ¤íŠ¸ ê°œì„ , ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

---

## ğŸ”„ ì „ì²´ ì²˜ë¦¬ í”Œë¡œìš°

```mermaid
flowchart TD
    subgraph Client ["ğŸ–¥ï¸ í´ë¼ì´ì–¸íŠ¸"]
        A1["ì˜¤ë””ì˜¤ íŒŒì¼ ì„ íƒ"]
        A2["ì²­í¬ ë¶„í•  ì—…ë¡œë“œ"]
    end

    subgraph Upload ["ğŸ“¤ ì—…ë¡œë“œ ë‹¨ê³„ (upload_controller.py)"]
        B1["POST /api/v1/upload/chunk"]
        B2{"ëª¨ë“  ì²­í¬\nìˆ˜ì‹  ì™„ë£Œ?"}
        B3["ì²­í¬ ë³‘í•©\nmerge_chunks_and_process"]
        B4["AnalysisWork ìƒì„±\nstatus: UPLOADING"]
    end

    subgraph Processing ["âš™ï¸ ì²˜ë¦¬ ë‹¨ê³„ (process.py)"]
        C1["process_audio_file ì‹œì‘"]
        
        subgraph Split ["VAD ë¶„í• "]
            C2["do_vad_split\nstatus: SPLITTING"]
            C3["split_audio_with_vad\n2ë¶„ ë‹¨ìœ„ ë¶„í• "]
        end
        
        subgraph Method ["ì²˜ë¦¬ ë°©ì‹ ì„ íƒ"]
            C4{"diarization_method?"}
            C5["stt_apigpt_diar_apigpt\nGPT ì „ì‚¬ + GPT í™”ìë¶„ë¦¬"]
            C6["stt_apiasm_diar_apiasm\nAssemblyAI ì „ì‚¬/í™”ìë¶„ë¦¬"]
            C7["stt_apigpt_diar_mlpyan\nGPT ì „ì‚¬ + Pyannote í™”ìë¶„ë¦¬"]
        end
        
        subgraph Transcribe ["ì „ì‚¬ (Transcription)"]
            D1["process_transcription\nstatus: TRANSCRIBING"]
            D2["OpenAI Whisper API\nor Deepgram API"]
            D3["ì„¸ê·¸ë¨¼íŠ¸ë³„ ë³‘ë ¬ ì²˜ë¦¬\nThreadPoolExecutor"]
        end
        
        subgraph Diarize ["í™”ì ë¶„ë¦¬ (Diarization)"]
            E1["diarize_audio_parallel\nstatus: DIARIZING"]
            E2["Pyannote\nSpeaker Diarization 3.1"]
            E3["í™”ìë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±"]
        end
        
        subgraph Improve ["ê°œì„  (Improvement)"]
            F1["status: IMPROVING"]
            F2["improve_transcription_lines\nGPT í…ìŠ¤íŠ¸ ê°œì„ "]
            F3["assign_speaker_to_lines\ní™”ì ë§¤í•‘"]
        end
    end

    subgraph Result ["ğŸ“Š ê²°ê³¼ ì €ì¥"]
        G1["TranscriptionResult ìƒì„±"]
        G2["save_transcription_result_json"]
        G3["save_analysis_work_json"]
        G4["status: COMPLETING"]
    end

    subgraph Query ["ğŸ” ê²°ê³¼ ì¡°íšŒ (upload_controller.py)"]
        H1["GET /api/v1/upload/status/uuid"]
        H2["GET /api/v1/upload/result/uuid"]
        H3["GET /api/v1/upload/result/step/uuid"]
    end

    subgraph Maum ["ğŸ§  ê°ì • ë¶„ì„ (maum_controller.py)"]
        I1["POST /api/v1/maum/uuid"]
        I2["analyze_sentiment_and_tense"]
        I3["make_psycho_timeline_chart_data"]
        I4["GET /api/v1/maum/chart/uuid"]
        I5["GET /api/v1/maum/data/uuid"]
    end

    A1 --> A2
    A2 --> B1
    B1 --> B4
    B4 --> B2
    B2 -->|No| B1
    B2 -->|Yes| B3
    B3 --> C1
    
    C1 --> C2
    C2 --> C3
    C3 --> C4
    
    C4 -->|apigpt| C5
    C4 -->|apiasm| C6
    C4 -->|mlpyan| C7
    
    C5 --> D1
    C6 --> D1
    C7 --> D1
    C7 --> E1
    
    D1 --> D2
    D2 --> D3
    
    E1 --> E2
    E2 --> E3
    
    D3 --> F1
    E3 --> F1
    F1 --> F2
    F2 --> F3
    
    F3 --> G1
    G1 --> G2
    G2 --> G3
    G3 --> G4
    
    G4 --> H1
    G4 --> H2
    G4 --> H3
    
    H2 --> I1
    I1 --> I2
    I2 --> I3
    I3 --> I4
    I3 --> I5
```

---

## ğŸ“Š ìƒíƒœ íë¦„ (AudioStatus)

```mermaid
stateDiagram-v2
    [*] --> PENDING: ì‘ì—… ìƒì„±
    PENDING --> UPLOADING: ì²­í¬ ì—…ë¡œë“œ ì‹œì‘
    UPLOADING --> SPLITTING: ëª¨ë“  ì²­í¬ ìˆ˜ì‹  ì™„ë£Œ
    SPLITTING --> DIARIZING: VAD ë¶„í•  ì™„ë£Œ
    SPLITTING --> TRANSCRIBING: VAD ë¶„í•  ì™„ë£Œ
    DIARIZING --> TRANSCRIBING: í™”ì ë¶„ë¦¬ ì™„ë£Œ
    TRANSCRIBING --> IMPROVING: ì „ì‚¬ ì™„ë£Œ
    IMPROVING --> COMPLETING: í…ìŠ¤íŠ¸ ê°œì„  ì™„ë£Œ
    COMPLETING --> [*]: ë¶„ì„ ì™„ë£Œ
    
    UPLOADING --> FAILED: ì˜¤ë¥˜ ë°œìƒ
    SPLITTING --> FAILED: ì˜¤ë¥˜ ë°œìƒ
    DIARIZING --> FAILED: ì˜¤ë¥˜ ë°œìƒ
    TRANSCRIBING --> FAILED: ì˜¤ë¥˜ ë°œìƒ
    IMPROVING --> FAILED: ì˜¤ë¥˜ ë°œìƒ
```

---

## ğŸ“ ì£¼ìš” íŒŒì¼ ë° ì—­í• 

| íŒŒì¼ | ì—­í•  |
|------|------|
| `backend/controllers/upload_controller.py` | íŒŒì¼ ì—…ë¡œë“œ ë° ê²°ê³¼ ì¡°íšŒ API |
| `backend/controllers/maum_controller.py` | ê°ì •/ì‹¬ë¦¬ ë¶„ì„ API |
| `backend/logic/voice_analysis/process.py` | í•µì‹¬ ì²˜ë¦¬ ë¡œì§ (ì „ì‚¬, í™”ìë¶„ë¦¬, ê°œì„ ) |
| `backend/logic/models.py` | ë°ì´í„° ëª¨ë¸ (AnalysisWork, AudioStatus, Segment) |
| `backend/logic/transcript_analysis/transcript_analysis_util.py` | í…ìŠ¤íŠ¸ ë¶„ì„ ìœ í‹¸ |

---

## ğŸ”§ ë‹¨ê³„ë³„ ìƒì„¸ ì„¤ëª…

### 1ï¸âƒ£ ì—…ë¡œë“œ ë‹¨ê³„ (UPLOADING)

**ì—”ë“œí¬ì¸íŠ¸**: `POST /api/v1/upload/chunk`

```
í´ë¼ì´ì–¸íŠ¸ â”€â”€ì²­í¬1â”€â”€> ì„œë²„
í´ë¼ì´ì–¸íŠ¸ â”€â”€ì²­í¬2â”€â”€> ì„œë²„
í´ë¼ì´ì–¸íŠ¸ â”€â”€ì²­í¬Nâ”€â”€> ì„œë²„ â”€â”€ë³‘í•©â”€â”€> ì™„ì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼
```

- ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ ì—¬ëŸ¬ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ì—…ë¡œë“œ
- ê° ì²­í¬ëŠ” `temp/uploading/{uuid}/` ë””ë ‰í† ë¦¬ì— ì €ì¥
- ëª¨ë“  ì²­í¬ ìˆ˜ì‹  ì™„ë£Œ ì‹œ `merge_chunks_and_process()` í˜¸ì¶œ
- `AnalysisWork` ê°ì²´ ìƒì„±í•˜ì—¬ ì‘ì—… ìƒíƒœ ê´€ë¦¬

### 2ï¸âƒ£ VAD ë¶„í•  ë‹¨ê³„ (SPLITTING)

**í•¨ìˆ˜**: `do_vad_split(analysis_job)`

```
ì›ë³¸ ì˜¤ë””ì˜¤ (10ë¶„)
    â”‚
    â”œâ”€â”€> ì„¸ê·¸ë¨¼íŠ¸ 1 (2ë¶„) â”€â”€> temp/splits/uuid/seg_0.wav
    â”œâ”€â”€> ì„¸ê·¸ë¨¼íŠ¸ 2 (2ë¶„) â”€â”€> temp/splits/uuid/seg_1.wav
    â”œâ”€â”€> ì„¸ê·¸ë¨¼íŠ¸ 3 (2ë¶„) â”€â”€> temp/splits/uuid/seg_2.wav
    â”œâ”€â”€> ì„¸ê·¸ë¨¼íŠ¸ 4 (2ë¶„) â”€â”€> temp/splits/uuid/seg_3.wav
    â””â”€â”€> ì„¸ê·¸ë¨¼íŠ¸ 5 (2ë¶„) â”€â”€> temp/splits/uuid/seg_4.wav
```

- **VAD** (Voice Activity Detection): ìŒì„±ì´ ìˆëŠ” êµ¬ê°„ë§Œ ê°ì§€
- ê¸°ë³¸ 2ë¶„(120ì´ˆ) ë‹¨ìœ„ë¡œ ì˜¤ë””ì˜¤ ë¶„í• 
- ë¬´ìŒ êµ¬ê°„ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë¶„í• í•˜ì—¬ ë¬¸ì¥ ëŠê¹€ ë°©ì§€

### 3ï¸âƒ£ ì²˜ë¦¬ ë°©ì‹ ì„ íƒ

| ë°©ì‹ | STT | í™”ìë¶„ë¦¬ | ì„¤ëª… |
|------|-----|----------|------|
| `stt_apigpt_diar_apigpt` | OpenAI GPT | OpenAI GPT | GPTë¡œ ì „ì‚¬+í™”ì ì¶”ë¡  |
| `stt_apiasm_diar_apiasm` | AssemblyAI | AssemblyAI | AssemblyAI í†µí•© ì‚¬ìš© |
| `stt_apigpt_diar_mlpyan` | OpenAI GPT | Pyannote | GPT ì „ì‚¬ + ML í™”ìë¶„ë¦¬ (ê¸°ë³¸) |
| `stt_apigpt_diar_mlpyan2` | OpenAI GPT | Pyannote | ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™” ë²„ì „ |

### 4ï¸âƒ£ ì „ì‚¬ ë‹¨ê³„ (TRANSCRIBING)

**í•¨ìˆ˜**: `process_transcription(analysis_job, split_segments)`

```mermaid
flowchart LR
    subgraph Parallel ["ë³‘ë ¬ ì²˜ë¦¬ (ThreadPoolExecutor)"]
        S1["ì„¸ê·¸ë¨¼íŠ¸ 1"] --> T1["OpenAI Whisper API"]
        S2["ì„¸ê·¸ë¨¼íŠ¸ 2"] --> T2["OpenAI Whisper API"]
        S3["ì„¸ê·¸ë¨¼íŠ¸ 3"] --> T3["OpenAI Whisper API"]
    end
    
    T1 --> M["ê²°ê³¼ ë³‘í•©"]
    T2 --> M
    T3 --> M
    
    M --> R["ì „ì‚¬ ê²°ê³¼\ní…ìŠ¤íŠ¸ + íƒ€ì„ìŠ¤íƒ¬í”„"]
```

- **ë³‘ë ¬ ì²˜ë¦¬**: `ThreadPoolExecutor`ë¡œ ì—¬ëŸ¬ ì„¸ê·¸ë¨¼íŠ¸ ë™ì‹œ ì²˜ë¦¬
- **API ì„ íƒ**: OpenAI Whisper API ë˜ëŠ” Deepgram API
- **ì¶œë ¥**: ê° ë‹¨ì–´/ë¬¸ì¥ì˜ ì‹œì‘/ì¢…ë£Œ ì‹œê°„ í¬í•¨

### 5ï¸âƒ£ í™”ì ë¶„ë¦¬ ë‹¨ê³„ (DIARIZING)

**í•¨ìˆ˜**: `diarize_audio_parallel(analysis_job, split_segments)`

```mermaid
flowchart LR
    A["ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸"] --> P["Pyannote\nSpeaker Diarization 3.1"]
    P --> D1["í™”ì 0: 0.0s ~ 5.2s"]
    P --> D2["í™”ì 1: 5.2s ~ 12.1s"]
    P --> D3["í™”ì 0: 12.1s ~ 18.5s"]
    P --> D4["í™”ì 1: 18.5s ~ 25.0s"]
```

- **Pyannote Audio**: HuggingFace ê¸°ë°˜ í™”ì ë¶„ë¦¬ ëª¨ë¸
- ê° êµ¬ê°„ì— í™”ì ID (SPEAKER_00, SPEAKER_01 ë“±) ë¶€ì—¬
- ì„¸ê·¸ë¨¼íŠ¸ë³„ í™”ì ìˆ˜ ìë™ ì¡°ì •

### 6ï¸âƒ£ ê°œì„  ë‹¨ê³„ (IMPROVING)

**í•¨ìˆ˜**: `improve_transcription_lines()`, `assign_speaker_to_lines_with_gpt()`

```
ì›ë³¸: "ì–´ ê·¸ë˜ì„œ ì €ëŠ” ìŒ ê·¸ë‹ˆê¹Œ..."
      â†“ GPT í…ìŠ¤íŠ¸ ê°œì„ 
ê°œì„ : "ê·¸ë˜ì„œ ì €ëŠ” ê·¸ëŸ¬ë‹ˆê¹Œ..."
      â†“ í™”ì ë§¤í•‘
ìµœì¢…: "[í™”ì 0] ê·¸ë˜ì„œ ì €ëŠ” ê·¸ëŸ¬ë‹ˆê¹Œ..."
```

- **í…ìŠ¤íŠ¸ ê°œì„ **: í•„ëŸ¬ì›Œë“œ ì œê±°, ë¬¸ì¥ ì •ë¦¬
- **í™”ì ë§¤í•‘**: ì „ì‚¬ ê²°ê³¼ì™€ í™”ìë¶„ë¦¬ ê²°ê³¼ ê²°í•©
- ë™ì¼ í™”ì ì—°ì† ë°œí™” ë³‘í•©

### 7ï¸âƒ£ ê²°ê³¼ ì €ì¥ (COMPLETING)

**ì €ì¥ ìœ„ì¹˜**: `uploads/{uuid}/`

```
uploads/{uuid}/
â”œâ”€â”€ id[{uuid}]_transcript.json      # ì „ì²´ ì „ì‚¬ ê²°ê³¼
â”œâ”€â”€ id[{uuid}]_ml_diarized.json     # í™”ì ë¶„ë¦¬ ê²°ê³¼
â”œâ”€â”€ id[{uuid}]_consecutive_segments.json  # ì—°ì† ì„¸ê·¸ë¨¼íŠ¸
â””â”€â”€ analysis_job.json               # ì‘ì—… ë©”íƒ€ë°ì´í„°
```

---

## ğŸ” ê²°ê³¼ ì¡°íšŒ API

### ìƒíƒœ ì¡°íšŒ
```bash
GET /api/v1/upload/status/{uuid}
```

**ì‘ë‹µ ì˜ˆì‹œ**:
```json
{
  "audio_uuid": "abc123",
  "status": "COMPLETING",
  "progress": {
    "steps": [
      {"step_name": "splitting", "status": "completed"},
      {"step_name": "transcribing", "status": "completed"},
      {"step_name": "improving", "status": "completed"}
    ],
    "percent_complete": 100
  }
}
```

### ê²°ê³¼ ì¡°íšŒ
```bash
GET /api/v1/upload/result/{uuid}
```

**ì‘ë‹µ ì˜ˆì‹œ**:
```json
{
  "audio_uuid": "abc123",
  "segments": [
    {
      "id": 0,
      "start": 0.0,
      "end": 5.2,
      "text": "ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ìƒë‹´ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.",
      "speaker": 0
    },
    {
      "id": 1,
      "start": 5.5,
      "end": 12.1,
      "text": "ë„¤, ê°ì‚¬í•©ë‹ˆë‹¤.",
      "speaker": 1
    }
  ],
  "speakers": [
    {"id": 0, "role": "counselor"},
    {"id": 1, "role": "client"}
  ]
}
```

---

## ğŸ§  ê°ì • ë¶„ì„ (Maum Analysis)

### ë¶„ì„ ì‹¤í–‰
```bash
POST /api/v1/maum/{uuid}
```

### ë¶„ì„ ë‚´ìš©

| ë¶„ì„ í•­ëª© | ì„¤ëª… |
|-----------|------|
| ë°œí™” ì†ë„ (Cadence) | í™”ìë³„ ë¶„ë‹¹ ë°œí™” ì†ë„ |
| ê°ì • ë¶„ì„ (Sentiment) | ê¸ì •/ë¶€ì • ê°ì • ìˆ˜ì¹˜ |
| ì‹œì œ ë¶„ì„ (Tense) | ê³¼ê±°/í˜„ì¬/ë¯¸ë˜ ì´ˆì  ë¹„ìœ¨ |
| íƒ€ì„ë¼ì¸ ì°¨íŠ¸ | ì‹œê°„ë³„ ì‹¬ë¦¬ ìƒíƒœ ì‹œê°í™” |

### ê²°ê³¼ ì¡°íšŒ
```bash
# ì°¨íŠ¸ ì´ë¯¸ì§€
GET /api/v1/maum/chart/{uuid}

# ë¶„ì„ ë°ì´í„° (JSON)
GET /api/v1/maum/data/{uuid}
```

---

## ğŸ“ ë°ì´í„° ëª¨ë¸

### AnalysisWork
```python
class AnalysisWork:
    id: str                    # UUID
    filename: str              # ì›ë³¸ íŒŒì¼ëª…
    status: AudioStatus        # í˜„ì¬ ìƒíƒœ
    steps: List[Dict]          # ë‹¨ê³„ë³„ ì§„í–‰ ì •ë³´
    options: Dict              # ì²˜ë¦¬ ì˜µì…˜
    result: TranscriptionResult # ìµœì¢… ê²°ê³¼
    error: Optional[str]       # ì—ëŸ¬ ë©”ì‹œì§€
```

### AudioStatus (Enum)
```python
class AudioStatus(str, Enum):
    PENDING = "pending"
    UPLOADING = "uploading"
    SPLITTING = "splitting"
    DIARIZING = "diarizing"
    TRANSCRIBING = "transcribing"
    IMPROVING = "improving"
    COMPLETING = "completing"
    FAILED = "failed"
```

### Segment
```python
class Segment:
    id: int           # ì„¸ê·¸ë¨¼íŠ¸ ID
    start: float      # ì‹œì‘ ì‹œê°„ (ì´ˆ)
    end: float        # ì¢…ë£Œ ì‹œê°„ (ì´ˆ)
    text: str         # ì „ì‚¬ëœ í…ìŠ¤íŠ¸
    speaker: int      # í™”ì ID
```

---

## âš¡ ì„±ëŠ¥ ìµœì í™” í¬ì¸íŠ¸

1. **ì²­í¬ ì—…ë¡œë“œ**: ëŒ€ìš©ëŸ‰ íŒŒì¼ ë„¤íŠ¸ì›Œí¬ ì•ˆì •ì„± í™•ë³´
2. **VAD ë¶„í• **: ì²˜ë¦¬ ë‹¨ìœ„ ìµœì í™” (2ë¶„)
3. **ë³‘ë ¬ ì²˜ë¦¬**: `ThreadPoolExecutor`ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ë™ì‹œ ì²˜ë¦¬
4. **ë¹„ë™ê¸° ì‹¤í–‰**: ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì²˜ë¦¬ (`daemon=True`)
5. **ê²°ê³¼ ìºì‹±**: JSON íŒŒì¼ë¡œ ì¤‘ê°„ ê²°ê³¼ ì €ì¥ ë° ì¬ì‚¬ìš©

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

```bash
# 1. ì„œë²„ ì‹¤í–‰
./run.sh

# 2. Swagger UI ì ‘ì†
open http://localhost:25500/doc

# 3. íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸
curl -X POST "http://localhost:25500/api/v1/upload/chunk" \
  -F "file=@audio.m4a" \
  -F "audio_uuid=test-uuid-123" \
  -F "chunk_index=0" \
  -F "total_chunks=1" \
  -F "original_filename=audio.m4a"

# 4. ìƒíƒœ í™•ì¸
curl "http://localhost:25500/api/v1/upload/status/test-uuid-123"

# 5. ê²°ê³¼ ì¡°íšŒ
curl "http://localhost:25500/api/v1/upload/result/test-uuid-123"
```

---

## ğŸ“š ì°¸ê³ 

- [OpenAI Whisper API](https://platform.openai.com/docs/guides/speech-to-text)
- [Pyannote Speaker Diarization](https://huggingface.co/pyannote/speaker-diarization-3.1)
- [AssemblyAI](https://www.assemblyai.com/docs)
- [Deepgram](https://developers.deepgram.com/)

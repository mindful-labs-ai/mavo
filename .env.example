# Mavo Server Environment Configuration
# Copy this file to .env and fill in your actual values

# OpenAI API Configuration (required for some features)
OPENAI_API_KEY=your_openai_api_key_here

# Server Configuration
PORT=25500
HOST=0.0.0.0
DEBUG=false

# Data Directories (leave as default for containerized deployment)
MAVO_DATASET_DIR=/app

# Whisper Model Configuration
WHISPER_MODEL=base  # Options: tiny, base, small, medium, large
USE_GPU=true  # Set to false if no GPU available

# OpenAI API Models
OPENAI_API_STT_MODEL=whisper-1
OPENAI_API_TRANSCRIPT_IMPROVEMENT_MODEL=gpt-4o-mini

# Diarization Settings
MAX_SPEAKERS=5

# Optional: Custom model paths (if using local models)
# WHISPER_MODEL_PATH=/path/to/custom/model
# PYANNOTE_MODEL_PATH=/path/to/pyannote/model

# Optional: GPU Device Selection (if multiple GPUs)
# CUDA_VISIBLE_DEVICES=0

# Optional: Memory limits (for resource-constrained environments)
# PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

import json
import os
import time
from openai import OpenAI
from typing import List
from concurrent.futures import ThreadPoolExecutor
import traceback
import copy
import re
from backend.logic.models import Segment
import backend.config as config
from backend.util.logger import get_logger
import re
import ollama

logger = get_logger(__name__)

# OpenAI client (lazy loading - will be loaded when needed)
_openai_client = None


def ask_ai_with_format(message, jsonformat, model="gemma3:4b"):
    if model.startswith("gpt"):
        return ask_openai_with_format(message, jsonformat, model)
    else:
        return ask_ollama_with_format(message, jsonformat, model)


def ask_ollama_with_format(messages, jsonformat, model="gemma3:4b"):
    response: ollama.ChatResponse = ollama.chat(
        model=model, messages=messages, format=jsonformat, stream=False
    )

    if response and "message" in response:
        return json.loads(response["message"]["content"], strict=False)
    else:
        return None


def ask_openai_with_format(messages, jsonformat, model="gpt-4.1-mini", temperature=0.3):
    completion = get_openai_client().chat.completions.create(
        model=model,  # or whichever model you prefer
        temperature=temperature,  # Adjust as needed
        # model="o3-mini",  # or whichever model you prefer
        messages=messages,
        response_format={
            "type": "json_schema",
            "json_schema": {
                "name": "structured_response",
                "strict": True,
                "schema": jsonformat,
            },
        },
    )
    raw_response = completion.choices[0].message.content
    structured_response = json.loads(raw_response)
    return structured_response


def create_openai_client(api_key):
    """
    Create an OpenAI client with proper error handling.

    Args:
        api_key: The OpenAI API key

    Returns:
        The OpenAI client or None if initialization fails
    """
    try:
        # Try to create the client with just the API key
        return OpenAI(api_key=api_key)
    except TypeError as e:
        err_msg = f"ERROR in create_openai_client: {e}\n with traceback:\n{traceback.format_exc()}"
        logger.error(err_msg)
        if "unexpected keyword argument 'proxies'" in str(e):
            # If the error is about proxies, try without http_client
            logger.warning(
                "Detected 'proxies' error, trying alternative initialization"
            )
            try:
                # Import the specific HTTP client to customize it
                import httpx

                # Create a client without proxies
                http_client = httpx.Client()
                return OpenAI(api_key=api_key, http_client=http_client)
            except Exception as e2:
                err_msg = f"ERROR in create_openai_client (alternative init): {e2}\n with traceback:\n{traceback.format_exc()}"
                logger.error(err_msg)
                return None
        else:
            logger.error(f"TypeError initializing OpenAI client: {e}")
            return None
    except Exception as e:
        err_msg = f"ERROR in create_openai_client: {e}\n with traceback:\n{traceback.format_exc()}"
        logger.error(err_msg)
        return None


def get_openai_client():
    """
    Get the OpenAI client, initializing it if necessary.

    Returns:
        The OpenAI client
    """
    global _openai_client
    if _openai_client is None:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            logger.warning("OPENAI_API_KEY not found in environment variables")
            return None

        logger.info("Initializing OpenAI client")
        _openai_client = create_openai_client(api_key)
        if _openai_client:
            logger.info("OpenAI client initialized successfully")
        else:
            logger.error("Failed to initialize OpenAI client")

    return _openai_client


def postprocess_segments(segments: List[dict]) -> List[dict]:
    """
    Send the segments to ChatGPT for text improvement and assignment of 'speaker'.
    Returns a list of improved segments with keys [id, start, end, text, speaker].
    """

    # 1. Prepare a JSON schema that ChatGPT must adhere to.
    json_schema = {
        "type": "object",
        "properties": {
            "segments": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "id": {"type": "integer"},
                        "start": {"type": "number"},
                        "end": {"type": "number"},
                        "text_raw": {"type": "string"},
                        "text": {"type": "string"},
                        "speaker": {"type": "integer"},
                    },
                    "required": ["id", "start", "end", "text", "text_raw", "speaker"],
                    "additionalProperties": False,
                },
            }
        },
        "required": ["segments"],
        "additionalProperties": False,
    }

    # 2. Construct our system and user messages.
    #    - System message: Tells ChatGPT to be a helpful assistant, keep meaning, correct grammar.
    #    - User message:  Passes the original segments as JSON,
    #                     instructs ChatGPT to add a "speaker" field for each segment.

    # "content": (
    #     "You are a helpful assistant that improves transcription text from a psychological counseling session. "
    #     "Read the whole dialogue of the counseling session, then think how to improve the text. "
    #     "Only correct clear errors such as spelling, or misheard words, and do not rephrase or paraphrase the original content. "
    #     "The text should be in Korean."
    #     "Assign a 'speaker' value (0, 1, 2, ...) for each segment. 0 is counselor, 1 is client1, 2 is client2, etc. Use 'text' field to determine the speaker."
    #     "Counselor tends to start the conversation more, ask more questions, cut-in more, use professional, empathetic, and clear language, often asking reflective and open-ended questions, "
    #     "providing guidance in a calm and supportive manner. "
    #     "If the context of the dialogue changes, it is likely that the counselor has intervened. "
    #     "Client tends to express personal emotions and experiences, sometimes in an informal or hesitant tone, "
    #     "and may ask for analysis or express uncertainty. "
    #     "Please process the text accordingly and return the improved transcription with the assigned speaker values."
    # )
    messages = [
        {"role": "system", "content": config.TRANSCRIPT_SYSTEM_PROMPT},
        # "Assign a 'speaker' value (0, 1, 2) for each segment, where 0 is counselor, 1 is client, and 2 is others."
        {
            "role": "user",
            "content": (
                "Here is the JSON input:\n\n"
                + json.dumps(segments, ensure_ascii=False)
                + "\n\n"
                "Please return a valid JSON object following this exact schema:\n"
                + json.dumps(json_schema, ensure_ascii=False)
                + "\n\n"
                "The output must be strictly valid JSON and must only contain the 'segments' array of objects, "
                "where each object has 'id', 'start', 'end', 'text', and 'speaker'."
            ),
        },
    ]

    # 3. Call ChatGPT with the response format set to our JSON schema.
    #    This ensures ChatGPT's response is strictly valid JSON.
    completion = get_openai_client().chat.completions.create(
        model=config.OPENAI_API_TRANSCRIPT_IMPROVEMENT_MODEL,  # or whichever model you prefer
        temperature=0.2,  # Adjust as needed
        messages=messages,
        response_format={
            "type": "json_schema",
            "json_schema": {
                "name": "structured_response",
                "strict": True,
                "schema": json_schema,
            },
        },
    )

    # 4. Extract the improved segments from the response.
    #    The property name here (completion.structured_response["segments"])
    #    corresponds to the root key in our JSON schema ("segments").
    # improved_segments = completion.structured_response["segments"]

    raw_response = completion.choices[0].message.content
    structured_response = json.loads(raw_response)
    improved_segments = structured_response["segments"]

    return improved_segments


def improve_transcription(segments: List[Segment]) -> List[Segment]:
    """
    Improve transcription segments using OpenAI API.
    """
    # 1. Prepare a JSON schema that ChatGPT must adhere to.
    json_schema = {
        "type": "object",
        "properties": {
            "segments": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "id": {"type": "integer"},
                        "start": {"type": "number"},
                        "end": {"type": "number"},
                        "text": {"type": "string"},
                        "speaker": {"type": "integer"},
                    },
                    "required": ["id", "start", "end", "text", "speaker"],
                    "additionalProperties": False,
                },
            }
        },
        "required": ["segments"],
        "additionalProperties": False,
    }

    # 2. Construct our system and user messages.
    #    - System message: Tells ChatGPT to be a helpful assistant, keep meaning, correct grammar.
    #    - User message:  Passes the original segments as JSON,
    #                     instructs ChatGPT to add a "speaker" field for each segment.
    segments_dict = [seg.__dict__ for seg in segments]
    messages = [
        {"role": "system", "content": config.TRANSCRIPT_SYSTEM_PROMPT},
        {
            "role": "user",
            "content": (
                "Here is the JSON input:\n\n"
                + json.dumps(segments_dict, ensure_ascii=False)
                + "\n\n"
                "Please return a valid JSON object following this exact schema:\n"
                + json.dumps(json_schema, ensure_ascii=False)
                + "\n\n"
                "The output must be strictly valid JSON and must only contain the 'segments' array of objects, "
                "where each object has 'id', 'start', 'end', 'text', and 'speaker'."
            ),
        },
    ]

    print("imporve_transcription messages", messages)

    # 3. Call ChatGPT with the response format set to our JSON schema.
    #    This ensures ChatGPT's response is strictly valid JSON.
    completion = get_openai_client().chat.completions.create(
        model=config.OPENAI_API_TRANSCRIPT_IMPROVEMENT_MODEL,  # or whichever model you prefer
        temperature=0.2,  # Adjust as needed
        messages=messages,
        response_format={
            "type": "json_schema",
            "json_schema": {
                "name": "structured_response",
                "strict": True,
                "schema": json_schema,
            },
        },
    )

    # 4. Extract the improved segments from the response.
    #    The property name here (completion.structured_response["segments"])
    #    corresponds to the root key in our JSON schema ("segments").
    # improved_segments = completion.structured_response["segments"]

    raw_response = completion.choices[0].message.content
    structured_response = json.loads(raw_response)
    improved_segments = structured_response["segments"]

    return improved_segments
    pass


def assign_speaker_to_lines_with_gpt(lines):
    #     prompt_text_improvement = """
    # This is psychological counseling session transcript.
    # Read whole text and guess how many speakers are there.
    # Counselor tends to start the conversation more, ask more questions, cut-in more, use professional, empathetic, and clear language, often asking reflective and open-ended questions, providing guidance in a calm and supportive manner.
    # There should be one counsler at leaset. And there should be at least one client, and max is 4 clients.
    # Assign speaker to each line, reading the lines.
    # Give me 'speaker' as an interger. 0 for 'counsler'. 1, 2, 3 ... for different clients.
    # """
    prompt_text_improvement = """
This is psychological counseling session transcript. There is one counselor and one client.
Counselor tends to start the conversation more, ask more questions, cut-in more, use professional, empathetic, and clear language, often asking reflective and open-ended questions, providing guidance in a calm and supportive manner.
Assign speaker to each line, reading the lines.
Give me 'speaker' as an interger. 0 for 'counsler'. 1 for 'client'.
"""

    text = ""
    for idx_line, line in enumerate(lines):
        text += f"IDX {idx_line}: {line}\n"

    messages = [
        {"role": "system", "content": prompt_text_improvement},
        {"role": "user", "content": text},
    ]

    json_schema = {  ## string list
        "type": "object",
        "properties": {
            "improved_lines": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "idx": {"type": "number"},
                        # "text": {"type": "string"},
                        "speaker": {"type": "number"},
                    },
                    # "required": ["idx","text", "speaker"],
                    "required": ["idx", "speaker"],
                    "additionalProperties": False,
                },
            }
        },
        "required": ["improved_lines"],
        "additionalProperties": False,
    }

    improved_lines = None
    try:
        completion = get_openai_client().chat.completions.create(
            model="gpt-4.1-mini",  # or whichever model you prefer
            temperature=0.3,  # Adjust as needed
            # model="o3-mini",  # or whichever model you prefer
            messages=messages,
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": "structured_response",
                    "strict": True,
                    "schema": json_schema,
                },
            },
        )
        # improved_lines_jsonstring = completion.choices[0].message['content']

        # improved_lines = json.loads(improved_lines_jsonstring)
        response_content = completion.choices[0].message.content
        # response_content = improved_lines_jsonstring
        response_data = json.loads(response_content)
        improved_lines = response_data.get("improved_lines", [])
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

    if improved_lines is None:
        logger.error("Failed to improve transcription text somehow")
        return None

    # print("improved_lines", improved_lines)

    return improved_lines


def improve_transcription_lines_with_speaker(text):
    """
    - improve transcription text with gpt-4o
    - correct transcription words using improved text with cosine similarity
    """

    prompt_text_improvement = """
The following text is the result of speech-to-text (STT) transcription from a psychological counseling session.

First, improve the text.
The STT contains errors. Correct the content according to the context.
When guessing the best text improvment, be aware that text often include expressions of emotions, personal feelings, and discussions of sensitive topics such as self-harm, suicidal thoughts, or intent to harm others.
Preserve the natural flow of spoken language. Use proper spacing and punctuation. Do not include explanations. Do not paraphrase.
Break lines at each sentence, as much as possible. Break lines at natural pauses, sentence endings, question marks or periods. Preserve the original meaning and flow of speech.
You may change the text to make it more natural and correct.

Second, guess how many speakers are there.

Third, assign speaker to each line, reading the lines.
There might be one counsler and at lease one client.
Give me improved 'improved_lines' json adding 'speaker' field, 
and expected values for 'speaker' is interger, 0 for consultant, 1, 2, 3 ... for clients.
"""
    #     "Counselor tends to start the conversation more, ask more questions, cut-in more, use professional, empathetic, and clear language, often asking reflective and open-ended questions, "
    #     "providing guidance in a calm and supportive manner. "
    #     "If the context of the dialogue changes, it is likely that the counselor has intervened. "
    #     "Client tends to express personal emotions and experiences, sometimes in an informal or hesitant tone, "

    if text is None:
        text = ""

    text = text.strip()
    ## remove leading and trailing quotes
    text = text.strip("\"'")
    ## remove leading and trailing newlines
    text = text.strip("\n")
    ## remove all whitespace and special characters in the text
    text = text.replace(" ", "").replace("\n", "").replace("\t", "").replace("\r", "")

    messages = [
        {"role": "system", "content": prompt_text_improvement},
        {"role": "user", "content": text},
    ]

    json_schema = {  ## string list
        "type": "object",
        "properties": {
            "improved_lines": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "text": {"type": "string"},
                        "speaker": {"type": "number"},
                    },
                    "required": ["text", "speaker"],
                    "additionalProperties": False,
                },
            }
        },
        "required": ["improved_lines"],
        "additionalProperties": False,
    }

    improved_lines = None
    try:
        completion = get_openai_client().chat.completions.create(
            model="gpt-4.1-mini",  # or whichever model you prefer
            temperature=0.2,  # Adjust as needed
            messages=messages,
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": "structured_response",
                    "strict": True,
                    "schema": json_schema,
                },
            },
        )
        # improved_lines_jsonstring = completion.choices[0].message['content']

        # improved_lines = json.loads(improved_lines_jsonstring)
        response_content = completion.choices[0].message.content
        # response_content = improved_lines_jsonstring
        response_data = json.loads(response_content)
        improved_lines = response_data.get("improved_lines", [])
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

    if improved_lines is None:
        logger.error("Failed to improve transcription text somehow")
        return None

    # print("improved_lines", improved_lines)

    return improved_lines


def improve_transcription_lines_parallel(text_splits):
    """
    - Improve transcription text with gpt-4o
    - Use parallel processing to speed up the process
    - Maintains the order of the original text_splits
    """
    futures = []
    print(f"Improving {len(text_splits)} text splits in parallel")
    with ThreadPoolExecutor(max_workers=6) as executor:
        for idx_text_split, text_split in enumerate(text_splits):
            print(f"Improving text split {idx_text_split} of {len(text_splits)}")
            futures.append(executor.submit(improve_transcription_lines, text_split))

    # Instead of using as_completed, iterate over futures to preserve order
    improved_lines = []
    for idx, future in enumerate(futures):
        lines = future.result()
        for idx_line, line in enumerate(lines):
            print(
                f"Improved lines length: {len(line)} for idx {idx_line}, text: {line}"
            )
            improved_lines.append(line)

    return improved_lines

    pass


def improve_transcription_lines(text):
    """
    - improve transcription text with gpt-4o
    - correct transcription words using improved text with cosine similarity
    """

    #     prompt_text_improvement = """
    # The following text is the result of speech-to-text (STT) transcription from a psychological counseling session. The STT contains errors.

    # First, Correct the text according to the context.
    # Preserve the natural flow of spoken language. Use proper spacing and punctuation. Do not include explanations. Do not paraphrase.
    # You may change the text to make it more natural and correct.
    # When guessing the best text improvment, be aware that text often include expressions of emotions, personal feelings, and discussions of sensitive topics such as self-harm, suicidal thoughts, or intent to harm others.

    # Second, break lines at each sentence aggressively. Break lines as much as possible.
    # Break lines at natural pauses, sentence endings, question marks or periods, and possible speaker changes. Preserve the original meaning and flow of speech.
    # """
    # You may change the text to make it more natural and correct.
    prompt_text_improvement = """
The following text is the result of speech-to-text (STT) transcription from a psychological counseling session.
The STT contains errors. Correct the content according to the context.
When guessing the best text improvment, be aware that text often include expressions of emotions, personal feelings, and discussions of sensitive topics such as self-harm, suicidal thoughts, or intent to harm others.
Preserve the natural flow of spoken language. Use proper spacing and punctuation. Do not include explanations. Do not paraphrase.
Break lines at each sentence very aggressively, as aggressively as possible.
Break lines at natural pauses, sentence endings, question marks, periods, commas, conjunctions, connectives, and possible speaker changes.
Preserve the original meaning and flow of speech.
You may change the text to make it more natural and correct.
"""

    #     """
    # The following text is the result of speech-to-text (STT) transcription from a psychological counseling session.
    # The STT output may contain recognition errors. Correct the content while preserving the original meaning and tone of the speaker.
    # This text may include expressions of emotions, personal feelings, and discussions of sensitive topics such as self-harm or suicidal thoughts.
    # Make only minimal edits necessary for clarity. Do not paraphrase or rephrase.
    # Break lines at the end of each sentence. Use appropriate spacing, punctuation, and line breaks.
    # Do not add explanations or summaries. Preserve the natural flow of spoken language.
    # """

    if text is None:
        text = ""

    text = text.strip()
    ## remove leading and trailing quotes
    text = text.strip("\"'")
    ## remove leading and trailing newlines
    text = text.strip("\n")
    ## remove all whitespace and special characters in the text
    text = text.replace(" ", "").replace("\n", "").replace("\t", "").replace("\r", "")

    messages = [
        {"role": "system", "content": prompt_text_improvement},
        {"role": "user", "content": text},
    ]

    json_schema = {  ## string list
        "type": "object",
        "properties": {
            "improved_lines": {"type": "array", "items": {"type": "string"}}
        },
        "required": ["improved_lines"],
        "additionalProperties": False,
    }

    improved_lines = None
    try:
        completion = get_openai_client().chat.completions.create(
            model="gpt-4.1-mini",  # or whichever model you prefer
            temperature=0.4,  # Adjust as needed
            messages=messages,
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": "structured_response",
                    "strict": True,
                    "schema": json_schema,
                },
            },
        )
        # improved_lines_jsonstring = completion.choices[0].message['content']

        # improved_lines = json.loads(improved_lines_jsonstring)
        response_content = completion.choices[0].message.content
        # response_content = improved_lines_jsonstring
        response_data = json.loads(response_content)
        improved_lines = response_data.get("improved_lines", [])
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

    if improved_lines is None:
        logger.error("Failed to improve transcription text somehow")
        return None

    return improved_lines


def get_seg_ts_with_speaker_infer_wo_skip(trans_segs_with_ts_raw):
    """
    - get transcription segments with diarization segments
    """
    input_text = ""

    for idx_seg, seg in enumerate(trans_segs_with_ts_raw):
        seg["idx"] = idx_seg
    for idx_seg, seg in enumerate(trans_segs_with_ts_raw):
        # input_text += f"text: {seg['text']}, start: {seg['start']}, end: {seg['end']}, diar_label: {seg['diar_label']}\n"
        text_in_seg = seg["text"]
        if len(text_in_seg) > 40:
            text_in_seg = text_in_seg[:15] + "..." + text_in_seg[-15:]
        elif len(text_in_seg) > 20:
            last_text = text_in_seg[-20:]
            is_special_char = re.match(r"^[^\w\s]+$", last_text)
            if is_special_char:
                text_in_seg = text_in_seg[:-20] + last_text
            else:
                text_in_seg = text_in_seg[:20] + "."
        # input_text += f"{seg['idx']}({seg['diar_label']}):{text_in_seg}\n"
        input_text += f"{seg['idx']}({-1}):{text_in_seg}\n"

    text = input_text

    # Counselor tends to start the conversation more, ask more questions, cut-in more, use professional, empathetic, and clear language, often asking reflective and open-ended questions, providing guidance in a calm and supportive manner.

    # Counselor tends to initiate the conversation, and guides the discussion, asks reflective, use empathetic and supportive language, open-ended questions; provides calm, supportive guidance, Tends to interrupt politely.
    # Client tends to express personal emotions, relationships, and experiences. The client's language may be less structured and more emotionally charged.

    # IDX: index of the segment
    # DIAR: diarization label. Same number means high probability of same speaker, but may have errors. -1 means no speaker is assigned.
    # TEXT: text of the segment. fragment of the text.

    prompt_text_improvement = """You are a helpful assistant to assign speaker information to diarization result.
There might be one Counsler and at one or more clients.
Read the text, and guess how many speakers are there.

Counselor tends to initiate the conversation, and guides the discussion, gives explanation, asks reflective, use empathetic and supportive language, open-ended questions; provides calm, supportive guidance. Tends to interrupt.

Given the data, assign speaker information to each segment.
Read the text, and assign the role of the speaker to each segment.

Data meaning is like this:
IDX: index of the segment
DIAR: diarization label. -1 means undecided.
TEXT: text of the segment. fragment of the text.

Data format is like this:
IDX(DIAR):TEXT

Output should be like this:
IDX: (same as input)
DIAR: (same as input, or guessed diar number)
SPEAKER: speaker number. 0 for Counselor, 1, 2, 3 ... for clients.
"""

    messages = [
        {"role": "system", "content": prompt_text_improvement},
        {"role": "user", "content": text},
    ]
    print(f"improving transcription with diarization result, text: {text}")

    json_schema = {  ## string list
        "type": "object",
        "properties": {
            "trans_segs_with_ts": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "idx": {"type": "number"},
                        "diar": {"type": "number"},
                        "speaker": {"type": "number"},
                    },
                    "required": ["idx", "diar", "speaker"],
                    "additionalProperties": False,
                },
            },
            "num_speakers": {"type": "number"},
        },
        "required": ["trans_segs_with_ts", "num_speakers"],
        "additionalProperties": False,
    }

    trans_segs_with_ts = None
    num_speakers = None
    try:
        completion = get_openai_client().chat.completions.create(
            # model="gpt-4.1-mini",  # or whichever model you prefer
            # model="gpt-4o",  # or whichever model you prefer
            model="gpt-4.1-mini",  # or whichever model you prefer
            temperature=0.4,  # Adjust as needed
            messages=messages,
            max_tokens=16384,  # default (max 16384 for gpt-4o, x2 for gpt-4.1)
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": "structured_response",
                    "strict": True,
                    "schema": json_schema,
                },
            },
        )
        response_content = completion.choices[0].message.content
        print(f"respone of seg_ts_with_diar: {response_content}")
        response_data = json.loads(response_content)
        trans_segs_with_ts = response_data.get("trans_segs_with_ts", [])
        num_speakers = response_data.get("num_speakers", None)
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

    if trans_segs_with_ts is None:
        logger.error("Failed to improve transcription text somehow")
        return None

    ## for all 'trans_segs_with_ts', find 'text' with 'idx' in 'trans_segs_with_ts_with_diar'
    for seg in trans_segs_with_ts:
        for seg_in in trans_segs_with_ts_raw:
            if seg["idx"] == seg_in["idx"]:
                seg["text"] = seg_in["text"]
                seg["start"] = seg_in["start"]
                seg["end"] = seg_in["end"]

    print("improved trans_segs_with_ts", trans_segs_with_ts)
    print("guessed num_speakers", num_speakers)

    return trans_segs_with_ts


def get_seg_ts_with_diar_with_speaker_infer_wo_skip(
    trans_segs_with_ts, diarization_segments
):
    """
    - get transcription segments with diarization segments
    """

    trans_segs_with_ts_with_diar = get_seg_ts_with_diar_wo_ai(
        trans_segs_with_ts, diarization_segments
    )

    if config.is_save_temp_files:
        save_path = config.TEMP_DIR / f"tmp055_trans_segs_with_ts_with_diar.json"
        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(trans_segs_with_ts_with_diar, f, ensure_ascii=False, indent=2)

    # Count each diar_label to understand distribution
    diar_count = {}
    for seg in trans_segs_with_ts_with_diar:
        diar_label = seg["diar_label"]
        if diar_label not in diar_count:
            diar_count[diar_label] = 0
        diar_count[diar_label] += 1

    ## num max speaker id of diarization_segments
    num_speakers_max_diar_seg = (
        max([seg["speaker"] for seg in diarization_segments]) + 1
    )
    print(
        f"Diarization label counts: {diar_count}, num_speakers_max_diar_seg: {num_speakers_max_diar_seg}"
    )

    input_text = ""
    for idx_seg, seg in enumerate(trans_segs_with_ts_with_diar):
        # input_text += f"text: {seg['text']}, start: {seg['start']}, end: {seg['end']}, diar_label: {seg['diar_label']}\n"
        text_in_seg = seg["text"]
        if len(text_in_seg) > 40:
            text_in_seg = text_in_seg[:15] + "..." + text_in_seg[-15:]
        elif len(text_in_seg) > 20:
            last_text = text_in_seg[-20:]
            is_special_char = re.match(r"^[^\w\s]+$", last_text)
            if is_special_char:
                text_in_seg = text_in_seg[:-20] + last_text
            else:
                text_in_seg = text_in_seg[:20] + "."
        input_text += f"{seg['idx']}({seg['diar_label']}):{text_in_seg}\n"
        # input_text += f"{seg['idx']}({-1}):{text_in_seg}\n"

    text = input_text

    # Counselor tends to start the conversation more, ask more questions, cut-in more, use professional, empathetic, and clear language, often asking reflective and open-ended questions, providing guidance in a calm and supportive manner.

    # Counselor tends to initiate the conversation, and guides the discussion, asks reflective, use empathetic and supportive language, open-ended questions; provides calm, supportive guidance, Tends to interrupt politely.
    # Client tends to express personal emotions, relationships, and experiences. The client's language may be less structured and more emotionally charged.

    # IDX: index of the segment
    # DIAR: diarization label. Same number means high probability of same speaker, but may have errors. -1 means no speaker is assigned.
    # TEXT: text of the segment. fragment of the text.

    prompt_text_improvement = """You are a helpful assistant to assign speaker information to diarization result.
There might be one Counsler and at one or more clients.
Read the text, and guess how many speakers are there.

Counselor tends to initiate the conversation, and guides the discussion, gives explanation, asks reflective, use empathetic and supportive language, open-ended questions; provides calm, supportive guidance. Tends to interrupt.
Client tends to tell their experiences, express emotions. Client tends to speak continuously.

Given the data, assign speaker information to each segment.
Read the text, and assign the role of the speaker to each segment.

Data meaning is like this:
IDX: index of the segment
DIAR: diarization label. -1 means undecided.
TEXT: text of the segment. fragment of the text.

Data format is like this:
IDX(DIAR):TEXT

Output should be like this:
IDX: (same as input)
DIAR: (same as input, or guessed diar number)
SPEAKER: speaker number. 0 for Counselor, 1, 2, 3 ... for clients.
"""

    messages = [
        {"role": "system", "content": prompt_text_improvement},
        {"role": "user", "content": text},
    ]
    print(f"improving transcription with diarization result, text: {text}")

    json_schema = {  ## string list
        "type": "object",
        "properties": {
            "trans_segs_with_ts": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "idx": {"type": "number"},
                        "diar": {"type": "number"},
                        "speaker": {"type": "number"},
                    },
                    "required": ["idx", "diar", "speaker"],
                    "additionalProperties": False,
                },
            },
            "num_speakers": {"type": "number"},
        },
        "required": ["trans_segs_with_ts", "num_speakers"],
        "additionalProperties": False,
    }

    trans_segs_with_ts = None
    num_speakers = None
    try:
        completion = get_openai_client().chat.completions.create(
            model="gpt-4.1-mini",  # or whichever model you prefer
            temperature=0.4,  # Adjust as needed
            messages=messages,
            max_tokens=16384,  # default (max 16384 for gpt-4o, x2 for gpt-4.1)
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": "structured_response",
                    "strict": True,
                    "schema": json_schema,
                },
            },
        )
        response_content = completion.choices[0].message.content
        print(f"respone of seg_ts_with_diar: {response_content}")
        response_data = json.loads(response_content)
        trans_segs_with_ts = response_data.get("trans_segs_with_ts", [])
        num_speakers = response_data.get("num_speakers", None)
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

    if trans_segs_with_ts is None:
        logger.error("Failed to improve transcription text somehow")
        return None

    ## for all 'trans_segs_with_ts', find 'text' with 'idx' in 'trans_segs_with_ts_with_diar'
    for seg in trans_segs_with_ts:
        for seg_in in trans_segs_with_ts_with_diar:
            if seg["idx"] == seg_in["idx"]:
                seg["text"] = seg_in["text"]
                seg["start"] = seg_in["start"]
                seg["end"] = seg_in["end"]

    print("improved trans_segs_with_ts", trans_segs_with_ts)
    print("guessed num_speakers", num_speakers)

    return trans_segs_with_ts

    pass


def get_seg_ts_with_diar_wo_ai_with_finding_closest(
    trans_segs_with_ts, diarization_segments
):
    """
    trans_segs_with_ts: [{'text': str, 'start': float, 'end': float}, ...]
    diarization_segments: [{'start': float, 'end': float, 'speaker': str/int}, ...]

    ê° ì „ì‚¬ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´, ë‹¤ì´ì–´ë¼ì´ì œì´ì…˜ ì„¸ê·¸ë¨¼íŠ¸ì™€ì˜ ê²¹ì¹˜ëŠ” ì‹œê°„ì„ ê³„ì‚°í•˜ì—¬
    ê°€ì¥ ê²¹ì¹˜ëŠ” ì‹œê°„ì´ í° ë‹¤ì´ì–´ë¼ì´ì œì´ì…˜ ì„¸ê·¸ë¨¼íŠ¸ì˜ í™”ì ì •ë³´ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤.
    If no overlap, find the closest segment by distance.

    Returns:
        list of dict: [{'text': str, 'start': float, 'end': float, 'speaker': str/int}, ...]
    """
    updated_segments = []
    for idx_seg, t_seg in enumerate(trans_segs_with_ts):
        t_start = t_seg["start"]
        t_end = t_seg["end"]

        max_overlap = 0
        min_distance = float("inf")
        assigned_speaker = -1

        for d_seg in diarization_segments:
            d_start = d_seg["start"]
            d_end = d_seg["end"]

            # ê²¹ì¹˜ëŠ” ì‹œê°„ ê³„ì‚°
            overlap_start = max(t_start, d_start)
            overlap_end = min(t_end, d_end)
            overlap = overlap_end - overlap_start

            # 0ë³´ë‹¤ í° ê²½ìš°ì—ë§Œ ê²¹ì¹œë‹¤ê³  íŒë‹¨
            if overlap > 0 and overlap > max_overlap:
                max_overlap = overlap
                assigned_speaker = d_seg["speaker"]
                min_distance = 0  # Reset minimum distance as we found an overlap

            # Calculate distance for non-overlapping segments
            elif overlap <= 0:
                # Calculate closest distance
                if t_end < d_start:  # Transcript ends before diarization starts
                    distance = d_start - t_end
                elif d_end < t_start:  # Diarization ends before transcript starts
                    distance = t_start - d_end
                else:
                    distance = 0  # Should not happen as we checked for overlap

                if distance < min_distance:
                    # Only assign if we haven't found an overlap yet
                    if max_overlap == 0:
                        min_distance = distance
                        assigned_speaker = d_seg["speaker"]

        # ê°€ì¥ ë§ì´ ê²¹ì¹˜ëŠ” í™”ì ì •ë³´ë¥¼ ì„¸ê·¸ë¨¼íŠ¸ì— ë‹´ëŠ”ë‹¤.
        updated_segments.append(
            {
                "idx": idx_seg,
                "text": t_seg["text"],
                "start": t_start,
                "end": t_end,
                "diar_label": assigned_speaker,
            }
        )

    return updated_segments


def get_seg_ts_with_diar_wo_ai(trans_segs_with_ts, diarization_segments):
    """
    trans_segs_with_ts: [{'text': str, 'start': float, 'end': float}, ...]
    diarization_segments: [{'start': float, 'end': float, 'speaker': str/int}, ...]

    ê° ì „ì‚¬ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´, ë‹¤ì´ì–´ë¼ì´ì œì´ì…˜ ì„¸ê·¸ë¨¼íŠ¸ì™€ì˜ ê²¹ì¹˜ëŠ” ì‹œê°„ì„ ê³„ì‚°í•˜ì—¬
    ê°€ì¥ ê²¹ì¹˜ëŠ” ì‹œê°„ì´ í° ë‹¤ì´ì–´ë¼ì´ì œì´ì…˜ ì„¸ê·¸ë¨¼íŠ¸ì˜ í™”ì ì •ë³´ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤.
    If no overlap, the diar_label remains -1.

    Returns:
        list of dict: [{'text': str, 'start': float, 'end': float, 'diar_label': str/int}, ...]
    """
    updated_segments = []
    for idx_seg, t_seg in enumerate(trans_segs_with_ts):
        t_start = t_seg["start"]
        t_end = t_seg["end"]

        max_overlap = 0
        assigned_speaker = -1  # Default to -1 (no speaker assigned)

        for d_seg in diarization_segments:
            d_start = d_seg["start"]
            d_end = d_seg["end"]

            # ê²¹ì¹˜ëŠ” ì‹œê°„ ê³„ì‚°
            overlap_start = max(t_start, d_start)
            overlap_end = min(t_end, d_end)
            overlap = overlap_end - overlap_start

            # 0ë³´ë‹¤ í° ê²½ìš°ì—ë§Œ ê²¹ì¹œë‹¤ê³  íŒë‹¨í•˜ê³ , ìµœëŒ€ ê²¹ì¹¨ì„ ì—…ë°ì´íŠ¸
            if overlap > 0 and overlap > max_overlap:
                max_overlap = overlap
                assigned_speaker = d_seg["speaker"]

        # ê°€ì¥ ë§ì´ ê²¹ì¹˜ëŠ” í™”ì ì •ë³´ë¥¼ ì„¸ê·¸ë¨¼íŠ¸ì— ë‹´ëŠ”ë‹¤.
        # If max_overlap remains 0, assigned_speaker will still be -1.
        updated_segments.append(
            {
                "idx": idx_seg,
                "text": t_seg["text"],
                "start": t_start,
                "end": t_end,
                "diar_label": assigned_speaker,
            }
        )

    return updated_segments


if __name__ == "__main__":

    prompt_text_improvement = """You are a helpful assistant to assign speaker information to diarization result.
There might be one Counsler and at one or more clients.
Read the text, and guess how many speakers are there.

Counselor tends to initiate the conversation, and guides the discussion, gives explanation, asks reflective, use empathetic and supportive language, open-ended questions; provides calm, supportive guidance. Tends to interrupt.
Client tends to tell their experiences, express emotions. Client tends to speak continuously.

Given the data, assign speaker information to each segment.
Read the text, and assign the role of the speaker to each segment.

Data meaning is like this:
IDX: index of the segment
DIAR: diarization label. -1 means undecided.
TEXT: text of the segment. fragment of the text.

Data format is like this:
IDX(DIAR):TEXT

Output should be like this:
IDX: (same as input)
DIAR: (same as input, or guessed diar number)
SPEAKER: speaker number. 0 for Counselor, 1, 2, 3 ... for clients.
"""

    text = """
1(0): ì•„, ë„¤, ì¹´ì¹´ì˜¤ë¼ê³ .
2(1): ì˜¤ëŠ˜ ë§‰ ì£¼ê°€ê°€ ì˜¬ëë‹¤ê³  ë§‰ ê·¸ëŸ¬ë˜ë°.
3(1): 15ë…„ 2ì›” 3ì¼ì´ê³ ìš”.
4(1): ìƒë‹´ ë°›ì•„ë³´ì‹  ê²½í—˜ì´ ìˆìœ¼ì‹œë„¤ìš”?
5(0): ì•„, ë„¤, í•œ ì¬ì‘ë…„ ë•Œ.
6(0): ê·¸ë•ŒëŠ” íšŒì‚¬ì—ì„œ ì˜ ì ì‘ ëª» í•´ê°€ì§€ê³  í•œ ë‹¬ì— ëª‡ ê°œ ë°›ì•˜ì—ˆì–´ìš”.
7(0): í•œ ë‹¬ì— í•œ ë²ˆ?
8(1): ì–´ë””ì„œ ë°›ìœ¼ì…¨ì–´ìš”?
9(0): ê·¸ ì´ë¦„ì´ ê¸°ì–µì´ ì•ˆ ë‚˜ëŠ”ë° ë‹¹ì‚°ì— ìˆëŠ”...
10(0): ì–´ë–¤ ë‹¹ì‚°?
11(1): ì—¬ê¸°ëŠ” ë­... ì•„, ì¢€ ë¹¨ë¦¬ ì‹œì‘í•´ë³¼ê¹Œë„ ìƒê°í–ˆëŠ”ë°.
12(1): ëˆ„ê°€ ê³„ì„¸ìš”?
13(1): ì €í¬ ì–´ë¨¸ë‹ˆ, ë‚¨ë™ìƒì´ê³ ìš”.
14(0): ê°™ì´ ì‚´ê³  ìˆì§„ ì•Šì•„ìš”.
15(1): ë„¤, ì•Œê² ìŠµë‹ˆë‹¤.
16(1): ê²°í˜¼í•˜ì‹œë ¤ê³  í•˜ëŠ”ë° ì¢€ ê·¸ëŸ° ì´ìŠˆ ê°€ì§€ê³  í•˜ì‹œê³ .
17(1): ì´ ë’¤ì—ëŠ” ì €í¬ëŠ” ìƒë‹´ ë¹„ë°€ë³´ì¥ì´ ì›ì¹™ì´ê³ ìš”.
18(1): ê·¸ë ‡ì§€ë§Œ ìì‹ ì´ë‚˜ íƒ€ì¸ì„ ìƒì˜í•  ì—¬ì§€ê°€ ìˆë‹¤ê³  í•  ë•ŒëŠ” ì œê°€ ë¦¬í¬íŠ¸í•´ì•¼ í•  ì˜ë¬´ê°€ ìˆì–´ì„œ.
19(1): ìì‹ ì´ë‚˜ íƒ€ì¸ì„ ìƒì˜í•œë‹¤ëŠ” ì˜ë¯¸ëŠ” ìì‚´ì˜ ì˜ì‚¬ê°€ ìˆê±°ë‚˜ íƒ€ì¸ì„ í•´í•˜ê±°ë‚˜ ì´ëŸ´ ë•ŒëŠ” ê·¸ê±¸ ë¦¬í¬íŠ¸í•´ì•¼ ëœë‹¤ëŠ” ì–˜ê¸°ê³ .
20(1): ê·¸ë¦¬ê³  ìƒë‹´ì€ ë…¹ìŒì„ ì „ì²´ë¡œ í•´ìš”.
21(2): ë…¹ìŒì„ í•˜ëŠ” ì´ìœ ëŠ” ì œê°€ ë†“ì¹˜ëŠ” ê²Œ ìˆì„ ìˆ˜ë„ ìˆê³ , ë˜ ì–´ë–¤ ê²½ìš°ëŠ” ìš°ë¦¬ ìˆ˜ì—° ì”¨ ì´ì•¼ê¸° ì´ì œ ìš°ë¦¬ ë‹¤ì‹œ ë“¤ì–´ë³´ë©´ì„œ ë˜ ì ê²€í•  ìˆ˜ë„ ìˆê³  ê·¸ë˜ì„œ.
22(2): ê·¸ëŸ° ë‚´ìš©ìœ¼ë¡œ ë™ì˜í•˜ì‹œê³  ì´ì œ í•˜ì‹œë©´ ë  ê²ƒ ê°™ì•„ìš”.
23(2): ì—¬ê¸°ì— ì‚¬ì¸í•´ ì£¼ì„¸ìš”.
24(2): ê·¸ë˜ì„œ ì˜¤ëŠ˜ ì´ë ‡ê²Œ ì–´ë µê²Œ ì‹œê°„ ë‚´ì…¨ëŠ”ë°, ê·¸ë˜ë„ ë­ê°€ ì¡°ê¸ˆ ë‹¬ë¼ì§€ë©´ ë‚´ê°€ ì—¬ê¸° ì˜¤ê¸¸ ì˜í–ˆë‹¤ ìƒê°í•˜ì‹¤ê¹Œìš”?
25(2): ê²°í˜¼ì„ ì§€ê¸ˆ ì•½ì†ì„ í•˜ê³  ê³„ì‹  ê±°ì˜ˆìš”?
26(2): ë„¤.
27(2): ì•„, ë„¤.
28(2): ê·¸ ë­”ê°€ ì œê°€ ë˜ê²Œ 4ë…„ ë„˜ê²Œ ì‚¬ê·„ ë‚¨ìì¹œêµ¬ë‘ ê²°í˜¼ì„ ì•½ì†ì„ í•˜ê³ , ê²°í˜¼ ì¤€ë¹„ë¥¼ ì§„í–‰ì„ í•˜ëŠ”ë°, ë­”ê°€ ì œê°€ í™•ì‹ ì´ ê³„ì† ì•ˆ ì„œê°€ì§€ê³  ê³„ì† í—¤ì–´ì§€ìê³ ë„ í•˜ê³ .
"""

    messages = [
        {"role": "system", "content": prompt_text_improvement},
        {"role": "user", "content": text},
    ]
    print(f"improving transcription with diarization result, text: {text}")

    json_schema = {  ## string list
        "type": "object",
        "properties": {
            "trans_segs_with_ts": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "idx": {"type": "number"},
                        "diar": {"type": "number"},
                        "speaker": {"type": "number"},
                    },
                    "required": ["idx", "diar", "speaker"],
                    "additionalProperties": False,
                },
            },
            "num_speakers": {"type": "number"},
        },
        "required": ["trans_segs_with_ts", "num_speakers"],
        "additionalProperties": False,
    }

    elap_times = []
    print("asking1")
    time_start = time.time()
    res1 = ask_ai_with_format(messages, json_schema, model="gemma3:4b")
    time_end = time.time()
    elap_times.append(time_end - time_start)
    print(f"res1 {time_end - time_start}s", res1)

    print("asking2")
    time_start = time.time()
    res2 = ask_ai_with_format(messages, json_schema, model="gpt-4.1-mini")
    time_end = time.time()
    elap_times.append(time_end - time_start)
    print(f"res2 {time_end - time_start}s", res2)

    print("asking3")
    time_start = time.time()
    res3 = ask_ai_with_format(messages, json_schema, model="gpt-4o")
    time_end = time.time()
    elap_times.append(time_end - time_start)
    print(f"res3 {time_end - time_start}s", res3)

    print("asking4")
    time_start = time.time()
    res4 = ask_ai_with_format(messages, json_schema, model="gpt-4o-mini")
    time_end = time.time()
    elap_times.append(time_end - time_start)
    print(f"res4 {time_end - time_start}s", res4)

    print("elap_times")
    for idx, elap_time in enumerate(elap_times):
        print(f"elap_time {idx}: {elap_time}s")

    pass


# ì‘ë‹µì„ ì‚¬ì „ì²˜ë¦¬í•´ì„œ \uXXXX escapeë¥¼ ë¬´íš¨í™” (ì˜ˆ: \u26 â†’ \\u26)
def safe_json_loads(s):
    try:
        return json.loads(s)
    except json.decoder.JSONDecodeError as e:
        print("ğŸ”´ JSONDecodeError ë°œìƒ! ë°±ì—… ë¡œë”© ì‹œë„.")
        print("ì—ëŸ¬ ë©”ì‹œì§€:", str(e))
        # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì œ ìˆì„ ê²½ìš° ëŒ€ì‘: \uXXXXë¥¼ ì„ì‹œë¡œ ë¬´íš¨í™”
        safe_s = re.sub(r"\\u(?![0-9a-fA-F]{4})", r"\\\\u", s)
        return json.loads(safe_s)


def assign_speaker_roles(result):
    """
    í™”ìë³„ ì—­í•  í• ë‹¹í•˜ëŠ” í•¨ìˆ˜

    Parameters:
        result (dict): ì „ì‚¬ ê²°ê³¼ ë°ì´í„°

    Returns:
        dict: ì—­í• ì´ í• ë‹¹ëœ ì „ì‚¬ ê²°ê³¼
    """

    client = get_openai_client()

    # 1. í™”ìë³„ë¡œ ë°œí™” ë‚´ìš© ëª¨ìœ¼ê¸° (ëŒ€í™” ìˆœì„œëŒ€ë¡œ)
    conversation_text = []

    # ì„¸ê·¸ë¨¼íŠ¸ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    sorted_segments = sorted(result["segments"], key=lambda x: x.get("start", 0))

    current_speaker = None
    current_text = []

    is_limit_text_when_infer = True
    max_speaker_occurencies = 7  ## set this 1000 if not want to limit.
    dict_speaker_occurencies = {}

    for segment in sorted_segments:
        if "speaker" in segment:
            speaker = segment["speaker"]
            text = segment["text"].strip()

            # í™”ìê°€ ë°”ë€Œë©´ ì´ì „ í…ìŠ¤íŠ¸ ì €ì¥í•˜ê³  ìƒˆë¡œ ì‹œì‘
            if (
                current_speaker is not None
                and current_speaker != speaker
                and current_speaker != -1
            ):
                if current_text:

                    count = dict_speaker_occurencies.get(current_speaker, 0)
                    if count < max_speaker_occurencies:
                        if is_limit_text_when_infer:
                            joined_text = " ".join(current_text)
                            tok_text = joined_text.split()
                            # if len(joined_text) > 100: ## with len
                            #     joined_text = joined_text[:100] + '...'
                            if len(tok_text) > 15:  ## with tok
                                joined_text = (
                                    " ".join(tok_text[:10])
                                    + " ... "
                                    + " ".join(tok_text[-3:])
                                )
                            conversation_text.append(
                                f"[sid:{current_speaker}] {joined_text}"
                            )
                        else:
                            conversation_text.append(
                                f"[sid:{current_speaker}] {' '.join(current_text)}"
                            )
                        dict_speaker_occurencies[current_speaker] = count + 1
                current_text = [text]
                current_speaker = speaker
            else:
                # ê°™ì€ í™”ìê°€ ê³„ì† ë§í•˜ëŠ” ê²½ìš°
                current_speaker = speaker
                current_text.append(text)

    # ë§ˆì§€ë§‰ í™”ìì˜ í…ìŠ¤íŠ¸ ì¶”ê°€
    if current_speaker is not None and current_text:
        conversation_text.append(f"[{current_speaker}] {' '.join(current_text)}")

    # í™”ìê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
    if not conversation_text:
        print("No speaker information found in the result.")
        return result

    # ëŒ€í™” í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
    conversation_string = "\n".join(conversation_text)

    # 2. OpenAI APIë¥¼ í†µí•´ ì—­í•  í• ë‹¹
    json_schema = {
        "type": "object",
        "properties": {
            "analysis": {
                "type": "object",
                "properties": {
                    "counsling_group_type": {
                        "type": "string",
                        "description": "Individual/Couple/Family/SupportGroup",
                    },
                    "counsling_about": {
                        "type": "string",
                        "description": "Topic of the counseling session",
                    },
                    "client_count": {
                        "type": "integer",
                        "description": "Number of clients excluding the counselor",
                    },
                    "speakers": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "sid": {"type": "integer", "description": "Speaker ID"},
                                "role": {
                                    "type": "integer",
                                    "description": "Speaker role. 0 for counselor, 1, 2, 3 ... for different clients.",
                                },
                                "role_detail": {
                                    "type": "string",
                                    "description": "Detailed description of speaker's role",
                                },
                                "role_nickname": {
                                    "type": "string",
                                    "description": "Nickname of speaker. Use real name if possible like '~~ì”¨' or relation name like 'ë‚¨ìì¹œêµ¬','ì—„ë§ˆ'.",
                                },
                                "confidence": {
                                    "type": "number",
                                    "description": "Confidence level of role assignment (0-1)",
                                },
                            },
                            "required": [
                                "sid",
                                "role",
                                "role_detail",
                                "role_nickname",
                                "confidence",
                            ],
                            "additionalProperties": False,
                        },
                    },
                },
                "required": [
                    "counsling_group_type",
                    "counsling_about",
                    "client_count",
                    "speakers",
                ],
                "additionalProperties": False,
            }
        },
        "required": ["analysis"],
        "additionalProperties": False,
    }

    #     Counselor tends to initiate the conversation, and guides the discussion, gives explanation, asks reflective, use empathetic and supportive language, open-ended questions; provides calm, supportive guidance. Tends to interrupt.

    # Counselor tends to initiate the conversation, and guides the discussion, asks reflective, use empathetic and supportive language, open-ended questions; provides calm, supportive guidance, Tends to interrupt politely.
    # Client tends to express personal emotions and experiences. The client's language may be less structured and more emotionally charged.
    # Counselor tends to initiate the conversation, ask open-ended questions, and guides the discussion, gives explanation, asks reflective, use empathetic and supportive language, open-ended questions; provides calm, supportive guidance. Tends to interrupt.

    # Counselor tends to ask open-ended questions, and guides the discussion, asks reflective, use empathetic and supportive language, open-ended questions; provides calm, supportive guidance. Tends to interrupt.
    # Client tends to express personal emotions and experiences.

    # API ìš”ì²­ ë©”ì‹œì§€ êµ¬ì„±
    messages = [
        {
            "role": "system",
            "content": "You are an expert in analyzing conversational data, especially in counseling sessions. Your task is to identify the roles of different speakers roles based on their speech patterns and content.",
        },
        {
            "role": "user",
            "content": f"""
Please analyze the following conversation and identify the roles of each speaker.
Assume this is a counseling session. Determine how many clients there are and assign roles to each speaker ID.
Note that speech diarization might be inaccurate, so multiple speaker IDs might actually belong to the same person.
Number of client is undecided, but it should be 1 or more, and less than 5.
         
**Guidelines for Role Identification**

**Counselor**  
- Uses openâ€‘ended questions to encourage elaboration (e.g., â€œHow did that make you feel?â€, â€œWhat was going through your mind at that moment?â€)  
- Reflects and paraphrases the clientâ€™s statements to demonstrate understanding (e.g., â€œSo, youâ€™re saying thatâ€¦â€, â€œIt sounds likeâ€¦â€).  
- Validates emotions with empathetic language (e.g., â€œI hear how difficult that was for you.â€)  
- Guides gently without prescribing solutions, inviting the client to find their own answers.  
- Maintains a calm, supportive toneâ€”steady pace and soft inflection.  
- Occasionally interrupts to clarify or summarize (e.g., â€œLet me pause you thereâ€”what Iâ€™m hearing isâ€¦â€).  
- Periodically summarizes key points to keep the session on track (e.g., â€œTo recap what youâ€™ve shared so farâ€¦â€).

**Client**  
- Expresses personal feelings, emotional states, and lived experiences (e.g., â€œI feel really anxious.â€ / â€œLast week, this happenedâ€¦â€).  
- Speaks in firstâ€‘person (â€œI feelâ€¦â€, â€œI experiencedâ€¦â€).  
- Shares concrete examples or memories from their life.  
- May ask for advice, reassurance, or confirmation (e.g., â€œIs this normal?â€, â€œWhat should I do?â€).  
- Shows emotional shifts or distress signals (pauses, voice tremors, sighs).  
- At times hesitates or selfâ€‘edits, reflecting difficulty in expressing feelings.

Conversation:
{conversation_string}

Provide your analysis in a structured format.
        """,
        },
    ]

    print(f"role infer message: {messages}")

    try:
        # OpenAI API í˜¸ì¶œ
        completion = client.chat.completions.create(
            model="gpt-4.1",
            temperature=0.4,
            messages=messages,
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": "structured_response",
                    "strict": True,
                    "schema": json_schema,
                },
            },
        )

        # ì‘ë‹µ ì²˜ë¦¬
        response_content = completion.choices[0].message.content
        print(f"role infer response: {response_content}")
        # analysis = json.loads(response_content)
        analysis = safe_json_loads(response_content)

        # 3. ê²°ê³¼ë¥¼ ì „ì‚¬ ë°ì´í„°ì— ì¶”ê°€
        result["speaker_analysis"] = analysis["analysis"]

        # í™”ì IDì— ì—­í•  ë§¤í•‘
        speaker_roles = {
            speaker["sid"]: speaker["role"]
            for speaker in analysis["analysis"]["speakers"]
        }
        ## ì¶”ê°€ ì½”ë“œ
        speaker_roles.update({-1: -1})

        # ì„¸ê·¸ë¨¼íŠ¸ì™€ ë‹¨ì–´ì— ì—­í•  ì •ë³´ ì¶”ê°€
        for segment in result["segments"]:
            if "speaker" in segment:
                segment["speaker_role"] = speaker_roles.get(segment["speaker"], -1)

                # ë‹¨ì–´ ìˆ˜ì¤€ì—ì„œë„ ì—­í•  ì •ë³´ ì¶”ê°€
                if "words" in segment:
                    for word in segment["words"]:
                        if "speaker" in word:
                            word["speaker_role"] = speaker_roles.get(
                                word.get("speaker", -1), -1
                            )

        print(
            f"Speaker role assignment completed. Found {analysis['analysis']['client_count']} clients."
        )
        print(f"Speaker roles: {speaker_roles}")

    except Exception as e:
        print(f"Error in speaker role assignment: {str(e)}")

    return result
